import requests
from bs4 import BeautifulSoup
from pymongo import MongoClient

# MongoDB setup
client = MongoClient("mongodb://localhost:27017/")
db = client["aetherreg"]
circulars_collection = db["circulars"]

# Fetch RBI circulars page
url = "https://www.rbi.org.in/Scripts/BS_PressReleaseDisplay.aspx"
print("ğŸ” Fetching RBI circulars page...")
response = requests.get(url)
soup = BeautifulSoup(response.content, "html.parser")

# Find PDF links
pdf_links = []
for link in soup.find_all("a", href=True):
    href = link["href"]
    if href.lower().endswith(".pdf"):
        full_url = "https://www.rbi.org.in" + href if href.startswith("/") else href
        title = link.get_text(strip=True)
        if not title:
            title = "Untitled Circular"
        pdf_links.append({"title": title, "url": full_url})

# Remove duplicates by URL
unique_links = {c["url"]: c for c in pdf_links}.values()
print(f"âœ… Found {len(unique_links)} unique circulars.\n")

# Save to MongoDB
inserted_count = 0
for circular in unique_links:
    if not circulars_collection.find_one({"url": circular["url"]}):  # avoid duplicates
        circulars_collection.insert_one(circular)
        inserted_count += 1
    print(f"ğŸ”¹ {circular['title']}\n   ğŸ“ {circular['url']}\n")

print(f"ğŸ—‚ï¸ {inserted_count} new circular(s) saved to MongoDB.")
